{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lubaina1904/diabetic-retinopathy-ml/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.float_ = np.float64\n"
      ],
      "metadata": {
        "id": "ysL_Xs2FPZYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ4mpMMx3EO7",
        "outputId": "77031824-7cac-4ef4-ec41-3a5a64c8be72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zmhsvgrrCB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694500e5-e5bb-47be-c83a-75eea6f5569c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: flwr==1.5.0 in /usr/local/lib/python3.12/dist-packages (1.5.0)\n",
            "Requirement already satisfied: cryptography<42.0.0,>=41.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr==1.5.0) (41.0.7)\n",
            "Requirement already satisfied: grpcio!=1.52.0,<2.0.0,>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from flwr==1.5.0) (1.76.0)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr==1.5.0) (0.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from flwr==1.5.0) (1.26.4)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from flwr==1.5.0) (3.20.3)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from flwr==1.5.0) (3.23.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<42.0.0,>=41.0.2->flwr==1.5.0) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio!=1.52.0,<2.0.0,>=1.48.2->flwr==1.5.0) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<42.0.0,>=41.0.2->flwr==1.5.0) (2.23)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.21)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\n",
            "Collecting opacus\n",
            "  Using cached opacus-1.5.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from opacus) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.8.0+cu126)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.12/dist-packages (from opacus) (1.16.3)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.3)\n",
            "Using cached opacus-1.5.4-py3-none-any.whl (254 kB)\n",
            "Installing collected packages: opacus\n",
            "Successfully installed opacus-1.5.4\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install flwr==1.5.0\n",
        "!pip install timm\n",
        "!pip install opacus\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn pillow tqdm\n",
        "\n",
        "# Verify installation\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create project structure\n",
        "!mkdir -p federated-dr/src\n",
        "!mkdir -p federated-dr/experiments\n",
        "!mkdir -p federated-dr/results\n",
        "!mkdir -p federated-dr/data/aptos\n",
        "\n",
        "# Change to project directory\n",
        "%cd federated-dr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUVyBC5rr0NE",
        "outputId": "307b3347-392b-4399-fece-ba9623837d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/federated-dr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "class DRDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.labels = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.labels.iloc[idx, 0]\n",
        "        img_path = f\"{self.img_dir}/{img_name}.png\"\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Preprocessing transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "TC2LGm833Z8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PHkE1ZtG3cVC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "ef72e3da-412d-48ec-f09c-43c08021451a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if your data exists\n",
        "data_path = '/content/drive/MyDrive/federated-dr/data/aptos/'\n",
        "\n",
        "print(\"üîç Checking if data exists...\")\n",
        "print(\"Path:\", data_path)\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    print(\"‚úÖ Folder found!\")\n",
        "    print(\"\\nüìÅ Contents:\")\n",
        "    contents = os.listdir(data_path)\n",
        "    for item in contents:\n",
        "        print(f\"  - {item}\")\n",
        "\n",
        "    # Check train_images\n",
        "    train_path = os.path.join(data_path, 'train_images')\n",
        "    if os.path.exists(train_path):\n",
        "        num_images = len(os.listdir(train_path))\n",
        "        print(f\"\\n‚úÖ Training images found: {num_images}\")\n",
        "    else:\n",
        "        print(\"‚ùå train_images folder not found\")\n",
        "else:\n",
        "    print(\"‚ùå Folder not found!\")\n",
        "    print(\"Please check the path and folder names\")"
      ],
      "metadata": {
        "id": "4Dtc_gr56b1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create project folders\n",
        "import os\n",
        "\n",
        "project_root = '/content/federated-dr'\n",
        "\n",
        "# Create all necessary folders\n",
        "folders = [\n",
        "    f'{project_root}/src',\n",
        "    f'{project_root}/experiments',\n",
        "    f'{project_root}/results',\n",
        "    f'{project_root}/notebooks'\n",
        "]\n",
        "\n",
        "for folder in folders:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    print(f\"‚úÖ Created: {folder}\")\n",
        "\n",
        "# Change to project directory\n",
        "os.chdir(project_root)\n",
        "print(f\"\\nüìÇ Current directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "id": "dz5wOPjio6fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/federated-dr/src/dataset.py\n",
        "# src/dataset.py\n",
        "\"\"\"\n",
        "DATASET MODULE - Data Loading & Preprocessing\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "\n",
        "class DiabeticRetinopathyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for Diabetic Retinopathy images\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file: Path to CSV with image names and labels\n",
        "            img_dir: Directory with all images\n",
        "            transform: torchvision transforms to apply\n",
        "        \"\"\"\n",
        "        # Read CSV\n",
        "        df = pd.read_csv(csv_file)\n",
        "\n",
        "        # FILTER: Only keep images that actually exist\n",
        "        print(\"Filtering CSV to only include available images...\")\n",
        "        available_images = []\n",
        "        available_labels = []\n",
        "\n",
        "        for idx, row in df.iterrows():\n",
        "            img_name = row['id_code']\n",
        "            label = row['diagnosis']\n",
        "\n",
        "            # Check if image exists (try both extensions)\n",
        "            img_path_png = os.path.join(img_dir, f\"{img_name}.png\")\n",
        "            img_path_jpeg = os.path.join(img_dir, f\"{img_name}.jpeg\")\n",
        "\n",
        "            if os.path.exists(img_path_png) or os.path.exists(img_path_jpeg):\n",
        "                available_images.append(img_name)\n",
        "                available_labels.append(label)\n",
        "\n",
        "        # Create filtered dataframe\n",
        "        self.labels_df = pd.DataFrame({\n",
        "            'id_code': available_images,\n",
        "            'diagnosis': available_labels\n",
        "        })\n",
        "\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Print dataset statistics\n",
        "        print(\"Loaded {} images (filtered from {} in CSV)\".format(\n",
        "            len(self.labels_df), len(df)))\n",
        "        print(\"Class distribution: {}\".format(Counter(self.labels_df['diagnosis'])))\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns total number of samples\"\"\"\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Loads and returns one sample\n",
        "        \"\"\"\n",
        "        # Get image name and label\n",
        "        img_name = self.labels_df.iloc[idx]['id_code']\n",
        "        label = self.labels_df.iloc[idx]['diagnosis']\n",
        "\n",
        "        # Load image (try .png first, then .jpeg)\n",
        "        img_path = os.path.join(self.img_dir, \"{}.png\".format(img_name))\n",
        "        if not os.path.exists(img_path):\n",
        "            img_path = os.path.join(self.img_dir, \"{}.jpeg\".format(img_name))\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(\"Error loading {}: {}\".format(img_path, e))\n",
        "            # Return a blank image if loading fails\n",
        "            image = Image.new('RGB', (224, 224), color='black')\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def get_transforms(mode='train', img_size=224):\n",
        "    \"\"\"\n",
        "    Get image transformations for train/val/test\n",
        "    \"\"\"\n",
        "\n",
        "    if mode == 'train':\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(degrees=15),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    else:  # val or test\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "\n",
        "# Test the dataset\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Testing Dataset Module\\n\")\n",
        "\n",
        "    # GOOGLE DRIVE PATHS\n",
        "    csv_path = \"/content/drive/MyDrive/federated-dr/data/aptos/train.csv\"\n",
        "    img_dir = \"/content/drive/MyDrive/federated-dr/data/aptos/train_images\"\n",
        "\n",
        "    # Create transforms\n",
        "    transform = get_transforms(mode='train')\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = DiabeticRetinopathyDataset(\n",
        "        csv_file=csv_path,\n",
        "        img_dir=img_dir,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    # Test __len__\n",
        "    print(\"\\nTotal images: {}\".format(len(dataset)))\n",
        "\n",
        "    # Test __getitem__\n",
        "    print(\"\\nLoading first 3 samples to verify...\")\n",
        "    for i in range(3):\n",
        "        image, label = dataset[i]\n",
        "        print(\"Sample {}: shape={}, label={}\".format(i, image.shape, label))\n",
        "\n",
        "    print(\"\\nDataset module working correctly!\")"
      ],
      "metadata": {
        "id": "Ocm9rkwVpCyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/federated-dr/src/dataset.py"
      ],
      "metadata": {
        "id": "Cks7lNPOpKuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/federated-dr')\n",
        "\n",
        "from src.dataset import DiabeticRetinopathyDataset, get_transforms\n",
        "\n",
        "# Create dataset\n",
        "csv_path = \"/content/drive/MyDrive/federated-dr/data/aptos/train.csv\"\n",
        "img_dir = \"/content/drive/MyDrive/federated-dr/data/aptos/train_images\"\n",
        "transform = get_transforms(mode='train')\n",
        "\n",
        "dataset = DiabeticRetinopathyDataset(csv_path, img_dir, transform)\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset ready with {len(dataset)} images\")\n",
        "print(f\"‚úÖ No errors - ready to proceed!\")"
      ],
      "metadata": {
        "id": "pfEGg6z4qGV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/federated-dr/src/model.py\n",
        "# src/model.py\n",
        "\"\"\"\n",
        "MODEL MODULE - Neural Network Architecture\n",
        "\n",
        "This defines the deep learning model for diabetic retinopathy classification.\n",
        "\n",
        "KEY CONCEPT: Transfer Learning\n",
        "- Use pretrained model (trained on ImageNet)\n",
        "- Replace final layer for our 5-class problem\n",
        "- Much faster and better than training from scratch\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm  # PyTorch Image Models library\n",
        "\n",
        "\n",
        "class DRClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Diabetic Retinopathy Classifier using Transfer Learning\n",
        "\n",
        "    Architecture:\n",
        "    Input (224√ó224√ó3) ‚Üí EfficientNet Backbone ‚Üí Features ‚Üí Classifier ‚Üí 5 classes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name='efficientnet_b0', num_classes=5, pretrained=True):\n",
        "        \"\"\"\n",
        "        Initialize the model\n",
        "\n",
        "        Args:\n",
        "            model_name: Which pretrained model to use\n",
        "            num_classes: Number of output classes (5 for DR)\n",
        "            pretrained: Whether to load ImageNet weights\n",
        "        \"\"\"\n",
        "        super(DRClassifier, self).__init__()\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Load pretrained backbone\n",
        "        # num_classes=0 means remove the classification head\n",
        "        self.backbone = timm.create_model(\n",
        "            model_name,\n",
        "            pretrained=pretrained,\n",
        "            num_classes=0  # Remove original classifier\n",
        "        )\n",
        "\n",
        "        # Get number of features from backbone\n",
        "        self.num_features = self.backbone.num_features\n",
        "\n",
        "        # Create our custom classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.3),  # Prevent overfitting\n",
        "            nn.Linear(self.num_features, num_classes)\n",
        "        )\n",
        "\n",
        "        print(\"Created {} model\".format(model_name))\n",
        "        print(\"Feature dimension: {}\".format(self.num_features))\n",
        "        print(\"Output classes: {}\".format(num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the network\n",
        "\n",
        "        Args:\n",
        "            x: Input images [batch_size, 3, 224, 224]\n",
        "\n",
        "        Returns:\n",
        "            logits: Raw scores [batch_size, num_classes]\n",
        "        \"\"\"\n",
        "        # Extract features using backbone\n",
        "        features = self.backbone(x)  # [batch_size, num_features]\n",
        "\n",
        "        # Classify\n",
        "        logits = self.classifier(features)  # [batch_size, num_classes]\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "def create_model(model_name='efficientnet_b0', num_classes=5, pretrained=True):\n",
        "    \"\"\"\n",
        "    Factory function to create a model\n",
        "\n",
        "    This is a convenient way to create models with default settings\n",
        "    \"\"\"\n",
        "    model = DRClassifier(\n",
        "        model_name=model_name,\n",
        "        num_classes=num_classes,\n",
        "        pretrained=pretrained\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Count total and trainable parameters in model\n",
        "    \"\"\"\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(\"Total parameters: {:,}\".format(total))\n",
        "    print(\"Trainable parameters: {:,}\".format(trainable))\n",
        "\n",
        "    return total, trainable\n",
        "\n",
        "\n",
        "# Test the model\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Testing Model Module\\n\")\n",
        "\n",
        "    # Create model\n",
        "    model = create_model(\n",
        "        model_name='efficientnet_b0',\n",
        "        num_classes=5,\n",
        "        pretrained=True\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "    # Count parameters\n",
        "    count_parameters(model)\n",
        "\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    # Test forward pass\n",
        "    print(\"Testing forward pass...\")\n",
        "    batch_size = 4\n",
        "    x = torch.randn(batch_size, 3, 224, 224)  # Fake batch of images\n",
        "\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    with torch.no_grad():  # Don't compute gradients\n",
        "        outputs = model(x)\n",
        "\n",
        "    print(\"Input shape: {}\".format(x.shape))\n",
        "    print(\"Output shape: {}\".format(outputs.shape))\n",
        "    print(\"Output (first sample): {}\".format(outputs[0]))\n",
        "\n",
        "    # Get predictions\n",
        "    probs = torch.softmax(outputs, dim=1)\n",
        "    predictions = torch.argmax(probs, dim=1)\n",
        "\n",
        "    print(\"\\nPredictions: {}\".format(predictions))\n",
        "    print(\"Probabilities (first sample): {}\".format(probs[0]))\n",
        "\n",
        "    print(\"\\nModel module working correctly!\")"
      ],
      "metadata": {
        "id": "Tc9mtShCqI-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "%run /content/federated-dr/src/model.py"
      ],
      "metadata": {
        "id": "JDUOblQhqjYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/federated-dr/src/train.py\n",
        "# src/train.py\n",
        "\"\"\"\n",
        "TRAINING MODULE - Handles model training and evaluation\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report\n",
        "import os\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    \"\"\"\n",
        "    Handles training and evaluation of models\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, train_loader, val_loader, device='cuda', learning_rate=0.001):\n",
        "        \"\"\"\n",
        "        Initialize trainer\n",
        "\n",
        "        Args:\n",
        "            model: The neural network\n",
        "            train_loader: DataLoader for training data\n",
        "            val_loader: DataLoader for validation data\n",
        "            device: 'cuda' or 'cpu'\n",
        "            learning_rate: Learning rate for optimizer\n",
        "        \"\"\"\n",
        "        self.model = model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.device = device\n",
        "\n",
        "        # Loss function\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Optimizer\n",
        "        self.optimizer = optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=1e-5\n",
        "        )\n",
        "\n",
        "        # Learning rate scheduler (removed 'verbose' parameter)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer,\n",
        "            mode='min',\n",
        "            factor=0.5,\n",
        "            patience=3\n",
        "        )\n",
        "\n",
        "        # Training history\n",
        "        self.history = {\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'val_kappa': []\n",
        "        }\n",
        "\n",
        "        self.best_val_kappa = 0.0\n",
        "\n",
        "        print(\"Trainer initialized\")\n",
        "        print(\"Device: {}\".format(device))\n",
        "        print(\"Learning rate: {}\".format(learning_rate))\n",
        "\n",
        "    def train_epoch(self):\n",
        "        \"\"\"\n",
        "        Train for one epoch\n",
        "\n",
        "        Returns:\n",
        "            Average loss and accuracy for this epoch\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        pbar = tqdm(self.train_loader, desc='Training')\n",
        "\n",
        "        for images, labels in pbar:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(images)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'loss': '{:.3f}'.format(running_loss / (pbar.n + 1)),\n",
        "                'acc': '{:.2f}%'.format(100. * correct / total)\n",
        "            })\n",
        "\n",
        "        epoch_loss = running_loss / len(self.train_loader)\n",
        "        epoch_acc = 100. * correct / total\n",
        "\n",
        "        return epoch_loss, epoch_acc\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"\n",
        "        Validate on validation set\n",
        "\n",
        "        Returns:\n",
        "            Loss, accuracy, and kappa score\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(self.val_loader, desc='Validating'):\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss = running_loss / len(self.val_loader)\n",
        "        val_acc = 100. * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
        "\n",
        "        kappa = cohen_kappa_score(all_labels, all_preds, weights='quadratic')\n",
        "\n",
        "        return val_loss, val_acc, kappa\n",
        "\n",
        "    def train(self, num_epochs, save_dir='results'):\n",
        "        \"\"\"\n",
        "        Main training loop\n",
        "\n",
        "        Args:\n",
        "            num_epochs: Number of epochs to train\n",
        "            save_dir: Directory to save checkpoints\n",
        "        \"\"\"\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Starting training for {} epochs\".format(num_epochs))\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        for epoch in range(1, num_epochs + 1):\n",
        "            print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            train_loss, train_acc = self.train_epoch()\n",
        "\n",
        "            val_loss, val_acc, val_kappa = self.validate()\n",
        "\n",
        "            # Update learning rate based on validation loss\n",
        "            old_lr = self.optimizer.param_groups[0]['lr']\n",
        "            self.scheduler.step(val_loss)\n",
        "            new_lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            # Print if LR changed\n",
        "            if new_lr != old_lr:\n",
        "                print(\"\\nLearning rate reduced: {:.6f} -> {:.6f}\".format(old_lr, new_lr))\n",
        "\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['val_kappa'].append(val_kappa)\n",
        "\n",
        "            print(\"\\nEpoch {} Summary:\".format(epoch))\n",
        "            print(\"  Train Loss: {:.4f} | Train Acc: {:.2f}%\".format(train_loss, train_acc))\n",
        "            print(\"  Val Loss: {:.4f} | Val Acc: {:.2f}% | Kappa: {:.4f}\".format(\n",
        "                val_loss, val_acc, val_kappa))\n",
        "\n",
        "            if val_kappa > self.best_val_kappa:\n",
        "                self.best_val_kappa = val_kappa\n",
        "                save_path = os.path.join(save_dir, 'best_model.pth')\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': self.model.state_dict(),\n",
        "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                    'val_kappa': val_kappa,\n",
        "                    'val_acc': val_acc\n",
        "                }, save_path)\n",
        "                print(\"  Saved best model (Kappa: {:.4f})\".format(val_kappa))\n",
        "\n",
        "            print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        print(\"Training complete!\")\n",
        "        print(\"Best validation kappa: {:.4f}\".format(self.best_val_kappa))\n",
        "\n",
        "        return self.history\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation with confusion matrix\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        dataloader: DataLoader for test data\n",
        "        device: 'cuda' or 'cpu'\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"Evaluating model...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    accuracy = 100. * np.sum(all_preds == all_labels) / len(all_labels)\n",
        "    kappa = cohen_kappa_score(all_labels, all_preds, weights='quadratic')\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EVALUATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Accuracy: {:.2f}%\".format(accuracy))\n",
        "    print(\"Kappa Score: {:.4f}\".format(kappa))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    class_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative']\n",
        "    print(\"\\n\" + classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "    results = {\n",
        "        'accuracy': accuracy,\n",
        "        'kappa': kappa,\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'predictions': all_preds.tolist(),\n",
        "        'labels': all_labels.tolist()\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Training module loaded successfully!\")\n",
        "    print(\"Import this module to use Trainer class\")"
      ],
      "metadata": {
        "id": "0zxqKMdvqn6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/federated-dr/src/utils.py\n",
        "# src/utils.py\n",
        "\"\"\"\n",
        "UTILITY FUNCTIONS\n",
        "\n",
        "Helper functions used across the project\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os\n",
        "\n",
        "\n",
        "def create_train_val_split(dataset, val_split=0.2, random_seed=42):\n",
        "    \"\"\"\n",
        "    Split dataset into train and validation sets\n",
        "\n",
        "    Args:\n",
        "        dataset: PyTorch Dataset\n",
        "        val_split: Fraction for validation (0.2 = 20%)\n",
        "        random_seed: For reproducibility\n",
        "\n",
        "    Returns:\n",
        "        train_dataset, val_dataset\n",
        "    \"\"\"\n",
        "    dataset_size = len(dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(val_split * dataset_size))\n",
        "\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_indices = indices[split:]\n",
        "    val_indices = indices[:split]\n",
        "\n",
        "    train_dataset = Subset(dataset, train_indices)\n",
        "    val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "    print(\"Train size: {}\".format(len(train_dataset)))\n",
        "    print(\"Val size: {}\".format(len(val_dataset)))\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n",
        "def get_dataloader(dataset, batch_size=32, shuffle=True, num_workers=2):\n",
        "    \"\"\"\n",
        "    Create DataLoader\n",
        "\n",
        "    Args:\n",
        "        dataset: PyTorch Dataset\n",
        "        batch_size: Samples per batch\n",
        "        shuffle: Randomize order\n",
        "        num_workers: Parallel data loading workers\n",
        "\n",
        "    Returns:\n",
        "        DataLoader\n",
        "    \"\"\"\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_training_history(history, save_path=None):\n",
        "    \"\"\"\n",
        "    Plot training curves\n",
        "\n",
        "    Args:\n",
        "        history: Dictionary with training metrics\n",
        "        save_path: Where to save plot (optional)\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    # Loss\n",
        "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Train')\n",
        "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Val')\n",
        "    axes[0].set_title('Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # Accuracy\n",
        "    axes[1].plot(epochs, history['train_acc'], 'b-', label='Train')\n",
        "    axes[1].plot(epochs, history['val_acc'], 'r-', label='Val')\n",
        "    axes[1].set_title('Accuracy')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy (%)')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    # Kappa\n",
        "    axes[2].plot(epochs, history['val_kappa'], 'g-')\n",
        "    axes[2].set_title('Validation Kappa Score')\n",
        "    axes[2].set_xlabel('Epoch')\n",
        "    axes[2].set_ylabel('Kappa')\n",
        "    axes[2].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(\"Saved plot to {}\".format(save_path))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, save_path=None):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels\n",
        "        y_pred: Predicted labels\n",
        "        save_path: Where to save plot (optional)\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative'],\n",
        "                yticklabels=['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative'])\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(\"Saved confusion matrix to {}\".format(save_path))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def save_results(results, save_path):\n",
        "    \"\"\"\n",
        "    Save results to JSON file\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary with results\n",
        "        save_path: Path to save file\n",
        "    \"\"\"\n",
        "    import json\n",
        "\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(\"Results saved to {}\".format(save_path))\n",
        "\n",
        "\n",
        "# Test\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Utility functions loaded successfully!\")"
      ],
      "metadata": {
        "id": "28nC7ilQqp6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/federated-dr/experiments\n",
        "import sys\n",
        "sys.path.append('/content/federated-dr')\n",
        "\n"
      ],
      "metadata": {
        "id": "LY2iyrAyM0O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/federated-dr/experiments/baseline.py\n",
        "# experiments/baseline.py\n",
        "\"\"\"\n",
        "BASELINE EXPERIMENT - Centralized Training\n",
        "\n",
        "This trains a model on all available data (centralized approach).\n",
        "This is our upper bound to compare federated learning against.\n",
        "\n",
        "HOW TO RUN:\n",
        "%run experiments/baseline.py\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/federated-dr')\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Import our modules\n",
        "from src.dataset import DiabeticRetinopathyDataset, get_transforms\n",
        "from src.model import create_model, count_parameters\n",
        "from src.train import Trainer, evaluate_model\n",
        "from src.utils import create_train_val_split, get_dataloader, plot_training_history, plot_confusion_matrix, save_results\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main training pipeline\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"BASELINE EXPERIMENT - CENTRALIZED TRAINING\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ==================== CONFIGURATION ====================\n",
        "    config = {\n",
        "        # Data paths (Google Drive)\n",
        "        'csv_file': '/content/drive/MyDrive/federated-dr/data/aptos/train.csv',\n",
        "        'img_dir': '/content/drive/MyDrive/federated-dr/data/aptos/train_images',\n",
        "\n",
        "        # Model\n",
        "        'model_name': 'efficientnet_b0',\n",
        "        'num_classes': 5,\n",
        "        'pretrained': True,\n",
        "\n",
        "        # Training\n",
        "        'batch_size': 32,\n",
        "        'num_epochs': 20,  # Start with 20 for testing\n",
        "        'learning_rate': 0.001,\n",
        "        'val_split': 0.2,\n",
        "        'num_workers': 2,\n",
        "\n",
        "        # Device\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "\n",
        "        # Paths\n",
        "        'save_dir': '/content/federated-dr/results/baseline',\n",
        "    }\n",
        "\n",
        "    os.makedirs(config['save_dir'], exist_ok=True)\n",
        "\n",
        "    print(\"\\nConfiguration:\")\n",
        "    for key, value in config.items():\n",
        "        print(\"  {}: {}\".format(key, value))\n",
        "\n",
        "    device = torch.device(config['device'])\n",
        "    print(\"\\nDevice: {}\".format(device))\n",
        "\n",
        "    # ==================== LOAD DATA ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Loading Dataset...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Create transforms\n",
        "    train_transform = get_transforms(mode='train')\n",
        "    val_transform = get_transforms(mode='val')\n",
        "\n",
        "    # Load full dataset\n",
        "    full_dataset = DiabeticRetinopathyDataset(\n",
        "        csv_file=config['csv_file'],\n",
        "        img_dir=config['img_dir'],\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    # Split into train/val\n",
        "    train_dataset, val_dataset = create_train_val_split(\n",
        "        full_dataset,\n",
        "        val_split=config['val_split'],\n",
        "        random_seed=42\n",
        "    )\n",
        "\n",
        "    # Apply val transform to val set\n",
        "    # This is a bit tricky - we need to access the underlying dataset\n",
        "    val_dataset.dataset.transform = val_transform\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = get_dataloader(\n",
        "        train_dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=config['num_workers']\n",
        "    )\n",
        "\n",
        "    val_loader = get_dataloader(\n",
        "        val_dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=False,\n",
        "        num_workers=config['num_workers']\n",
        "    )\n",
        "\n",
        "    print(\"Train batches: {}\".format(len(train_loader)))\n",
        "    print(\"Val batches: {}\".format(len(val_loader)))\n",
        "\n",
        "    # ==================== CREATE MODEL ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Creating Model...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    model = create_model(\n",
        "        model_name=config['model_name'],\n",
        "        num_classes=config['num_classes'],\n",
        "        pretrained=config['pretrained']\n",
        "    )\n",
        "\n",
        "    count_parameters(model)\n",
        "\n",
        "    # ==================== TRAIN ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Training Model...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        device=device,\n",
        "        learning_rate=config['learning_rate']\n",
        "    )\n",
        "\n",
        "    start_time = datetime.now()\n",
        "    # Train the model\n",
        "    history = trainer.train(\n",
        "        num_epochs=config['num_epochs'],\n",
        "        save_dir=config['save_dir']\n",
        "    )\n",
        "\n",
        "    end_time = datetime.now()\n",
        "    training_time = (end_time - start_time).total_seconds()\n",
        "\n",
        "    print(\"\\nTraining time: {:.2f} minutes\".format(training_time / 60))\n",
        "\n",
        "    # ==================== EVALUATE ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Final Evaluation...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Load best model\n",
        "    checkpoint = torch.load(\n",
        "    os.path.join(config['save_dir'], 'best_model.pth'),\n",
        "    map_location=device,\n",
        "    weights_only=False\n",
        ")\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Evaluate\n",
        "    results = evaluate_model(model, val_loader, device)\n",
        "\n",
        "    # ==================== VISUALIZE ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Creating Visualizations...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Plot training history\n",
        "    plot_training_history(\n",
        "        history,\n",
        "        save_path=os.path.join(config['save_dir'], 'training_history.png')\n",
        "    )\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plot_confusion_matrix(\n",
        "        results['labels'],\n",
        "        results['predictions'],\n",
        "        save_path=os.path.join(config['save_dir'], 'confusion_matrix.png')\n",
        "    )\n",
        "\n",
        "    # ==================== SAVE RESULTS ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Saving Results...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    final_results = {\n",
        "        'config': config,\n",
        "        'history': history,\n",
        "        'evaluation': {\n",
        "            'accuracy': results['accuracy'],\n",
        "            'kappa': results['kappa'],\n",
        "            'confusion_matrix': results['confusion_matrix']\n",
        "        },\n",
        "        'training_time_minutes': training_time / 60,\n",
        "        'best_val_kappa': trainer.best_val_kappa,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    save_results(\n",
        "        final_results,\n",
        "        os.path.join(config['save_dir'], 'results.json')\n",
        "    )\n",
        "\n",
        "    # ==================== SUMMARY ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EXPERIMENT SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"Best Validation Accuracy: {:.2f}%\".format(results['accuracy']))\n",
        "    print(\"Best Validation Kappa: {:.4f}\".format(results['kappa']))\n",
        "    print(\"Training Time: {:.2f} minutes\".format(training_time / 60))\n",
        "    print(\"Model saved to: {}\".format(config['save_dir']))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\nBaseline experiment complete!\")\n",
        "    print(\"Check the results folder for:\")\n",
        "    print(\"  - best_model.pth (trained model)\")\n",
        "    print(\"  - training_history.png (loss/accuracy curves)\")\n",
        "    print(\"  - confusion_matrix.png (prediction analysis)\")\n",
        "    print(\"  - results.json (all metrics)\")\n",
        "\n",
        "    return final_results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        results = main()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nTraining interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(\"\\n\\nError occurred: {}\".format(e))\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "iM2jaBaWqwln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just save the file first (don't run yet - will take time)\n",
        "print(\"Baseline experiment script created!\")\n",
        "print(\"File: /content/federated-dr/experiments/baseline.py\")"
      ],
      "metadata": {
        "id": "gVXyLEPxq8Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/federated-dr/src/client.py\n",
        "# src/client.py\n",
        "\"\"\"\n",
        "FEDERATED LEARNING CLIENT - Hospital Side\n",
        "\n",
        "This represents ONE hospital in the federated learning system.\n",
        "\n",
        "Key concept: Train locally, share only model updates!\n",
        "\"\"\"\n",
        "\n",
        "import flwr as fl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Tuple\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class HospitalClient(fl.client.NumPyClient):\n",
        "    \"\"\"\n",
        "    Federated Learning Client using FedAvg algorithm\n",
        "\n",
        "    This is what runs at each hospital:\n",
        "    1. Receives global model from server\n",
        "    2. Trains on local data\n",
        "    3. Sends updated weights back\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        device: str = 'cuda',\n",
        "        learning_rate: float = 0.001,\n",
        "        local_epochs: int = 3\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize client\n",
        "\n",
        "        Args:\n",
        "            model: Neural network\n",
        "            train_loader: This hospital's training data\n",
        "            val_loader: This hospital's validation data\n",
        "            device: 'cuda' or 'cpu'\n",
        "            learning_rate: Learning rate for local training\n",
        "            local_epochs: How many epochs to train per FL round\n",
        "        \"\"\"\n",
        "        self.model = model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.device = device\n",
        "        self.local_epochs = local_epochs\n",
        "\n",
        "        # Optimizer and loss\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr=learning_rate\n",
        "        )\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        print(\"Hospital client initialized\")\n",
        "        print(\"  Training samples: {}\".format(len(train_loader.dataset)))\n",
        "        print(\"  Local epochs per round: {}\".format(local_epochs))\n",
        "\n",
        "    def get_parameters(self, config: Dict) -> List[np.ndarray]:\n",
        "        \"\"\"\n",
        "        Extract model parameters as numpy arrays\n",
        "\n",
        "        Called by server to get current model weights\n",
        "\n",
        "        Returns:\n",
        "            List of model weights as numpy arrays\n",
        "        \"\"\"\n",
        "        return [val.cpu().numpy() for val in self.model.state_dict().values()]\n",
        "\n",
        "    def set_parameters(self, parameters: List[np.ndarray]) -> None:\n",
        "        \"\"\"\n",
        "        Load parameters into model\n",
        "\n",
        "        Called by server to send global model to this hospital\n",
        "\n",
        "        Args:\n",
        "            parameters: List of model weights as numpy arrays\n",
        "        \"\"\"\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        parameters: List[np.ndarray],\n",
        "        config: Dict\n",
        "    ) -> Tuple[List[np.ndarray], int, Dict]:\n",
        "        \"\"\"\n",
        "        Train model on local data\n",
        "\n",
        "        This is the CORE of federated learning!\n",
        "\n",
        "        Steps:\n",
        "        1. Receive global model\n",
        "        2. Train on local hospital data\n",
        "        3. Return updated weights\n",
        "\n",
        "        Args:\n",
        "            parameters: Global model weights from server\n",
        "            config: Configuration dictionary\n",
        "\n",
        "        Returns:\n",
        "            - Updated model parameters\n",
        "            - Number of training samples\n",
        "            - Metrics dictionary\n",
        "        \"\"\"\n",
        "        # 1. Set global parameters\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        # 2. Train locally\n",
        "        print(\"\\nTraining locally for {} epochs...\".format(self.local_epochs))\n",
        "        train_loss, train_acc = self._train_local()\n",
        "\n",
        "        # 3. Return updated parameters\n",
        "        print(\"Local training complete - Loss: {:.4f}, Acc: {:.2f}%\".format(\n",
        "            train_loss, train_acc))\n",
        "\n",
        "        return (\n",
        "            self.get_parameters(config={}),\n",
        "            len(self.train_loader.dataset),\n",
        "            {\"train_loss\": train_loss, \"train_acc\": train_acc}\n",
        "        )\n",
        "\n",
        "    def evaluate(\n",
        "        self,\n",
        "        parameters: List[np.ndarray],\n",
        "        config: Dict\n",
        "    ) -> Tuple[float, int, Dict]:\n",
        "        \"\"\"\n",
        "        Evaluate global model on local data\n",
        "\n",
        "        Tests how well the global model works for this hospital\n",
        "\n",
        "        Args:\n",
        "            parameters: Global model weights\n",
        "            config: Configuration dictionary\n",
        "\n",
        "        Returns:\n",
        "            - Loss value\n",
        "            - Number of samples\n",
        "            - Metrics dictionary\n",
        "        \"\"\"\n",
        "        # Set global parameters\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        # Evaluate\n",
        "        loss, accuracy = self._evaluate_local()\n",
        "\n",
        "        return (\n",
        "            loss,\n",
        "            len(self.val_loader.dataset),\n",
        "            {\"accuracy\": accuracy}\n",
        "        )\n",
        "\n",
        "    def _train_local(self) -> Tuple[float, float]:\n",
        "        \"\"\"\n",
        "        Local training loop\n",
        "\n",
        "        This happens INSIDE the hospital - data doesn't leave!\n",
        "\n",
        "        Returns:\n",
        "            Average loss and accuracy\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for epoch in range(self.local_epochs):\n",
        "            for images, labels in self.train_loader:\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        avg_loss = total_loss / (len(self.train_loader) * self.local_epochs)\n",
        "        accuracy = 100. * correct / total\n",
        "\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "    def _evaluate_local(self) -> Tuple[float, float]:\n",
        "        \"\"\"\n",
        "        Local evaluation\n",
        "\n",
        "        Returns:\n",
        "            Average loss and accuracy\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in self.val_loader:\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        avg_loss = total_loss / len(self.val_loader)\n",
        "        accuracy = 100. * correct / total\n",
        "\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def create_hospital_splits(dataset, num_hospitals=4, random_seed=42):\n",
        "    \"\"\"\n",
        "    Split data into \"hospitals\" with different distributions (non-IID)\n",
        "\n",
        "    This simulates real-world federated learning where each hospital\n",
        "    has different patient populations\n",
        "\n",
        "    Args:\n",
        "        dataset: Full dataset\n",
        "        num_hospitals: Number of hospitals to simulate\n",
        "        random_seed: For reproducibility\n",
        "\n",
        "    Returns:\n",
        "        List of datasets, one per hospital\n",
        "    \"\"\"\n",
        "    from torch.utils.data import Subset\n",
        "    from collections import defaultdict\n",
        "\n",
        "    # Get all labels\n",
        "    if hasattr(dataset, 'labels_df'):\n",
        "        all_labels = dataset.labels_df['diagnosis'].values\n",
        "        all_indices = list(range(len(dataset)))\n",
        "    else:\n",
        "        # It's a Subset\n",
        "        all_labels = [dataset.dataset.labels_df.iloc[i]['diagnosis']\n",
        "                     for i in dataset.indices]\n",
        "        all_indices = dataset.indices\n",
        "\n",
        "    # Group indices by class\n",
        "    class_indices = defaultdict(list)\n",
        "    for idx, label in zip(all_indices, all_labels):\n",
        "        class_indices[label].append(idx)\n",
        "\n",
        "    # Define distributions for each hospital\n",
        "    # These are intentionally different (non-IID)\n",
        "    distributions = [\n",
        "        [0.40, 0.20, 0.20, 0.10, 0.10],  # Hospital 1: Mostly healthy\n",
        "        [0.20, 0.15, 0.15, 0.25, 0.25],  # Hospital 2: More severe cases\n",
        "        [0.30, 0.25, 0.20, 0.15, 0.10],  # Hospital 3: Balanced\n",
        "        [0.25, 0.25, 0.25, 0.15, 0.10],  # Hospital 4: Moderate\n",
        "    ]\n",
        "\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    hospital_datasets = []\n",
        "\n",
        "    for h_id, dist in enumerate(distributions[:num_hospitals]):\n",
        "        hospital_indices = []\n",
        "\n",
        "        # Calculate samples per class for this hospital\n",
        "        total_samples_per_hospital = len(all_indices) // num_hospitals\n",
        "\n",
        "        for class_id, proportion in enumerate(dist):\n",
        "            num_samples = int(total_samples_per_hospital * proportion)\n",
        "\n",
        "            available = class_indices[class_id]\n",
        "            if len(available) >= num_samples:\n",
        "                sampled = np.random.choice(\n",
        "                    available,\n",
        "                    size=num_samples,\n",
        "                    replace=False\n",
        "                ).tolist()\n",
        "                hospital_indices.extend(sampled)\n",
        "\n",
        "                # Remove sampled indices so they're not reused\n",
        "                for idx in sampled:\n",
        "                    class_indices[class_id].remove(idx)\n",
        "\n",
        "        # Create dataset for this hospital\n",
        "        if hasattr(dataset, 'labels_df'):\n",
        "            hospital_dataset = Subset(dataset, hospital_indices)\n",
        "        else:\n",
        "            # Map to original dataset indices\n",
        "            original_indices = [dataset.dataset.labels_df.index[i]\n",
        "                              for i in hospital_indices]\n",
        "            hospital_dataset = Subset(dataset.dataset, original_indices)\n",
        "\n",
        "        hospital_datasets.append(hospital_dataset)\n",
        "\n",
        "        print(\"Hospital {}: {} samples\".format(h_id + 1, len(hospital_dataset)))\n",
        "\n",
        "    return hospital_datasets\n",
        "\n",
        "\n",
        "# Test\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Federated learning client module loaded!\")\n",
        "    print(\"This module contains:\")\n",
        "    print(\"  - HospitalClient: FL client implementation\")\n",
        "    print(\"  - create_hospital_splits: Create non-IID data splits\")"
      ],
      "metadata": {
        "id": "rauW49dCrAH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/federated-dr/src/client.py"
      ],
      "metadata": {
        "id": "j5FdBUL8rCrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/federated-dr/experiments/fedavg.py\n",
        "# experiments/fedavg.py\n",
        "\"\"\"\n",
        "FEDERATED LEARNING EXPERIMENT - FedAvg\n",
        "\n",
        "Simulates 4 hospitals training collaboratively WITHOUT sharing data!\n",
        "\n",
        "HOW TO RUN:\n",
        "%run experiments/fedavg.py\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/federated-dr')\n",
        "\n",
        "import torch\n",
        "import flwr as fl\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from datetime import datetime\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Import our modules\n",
        "from src.dataset import DiabeticRetinopathyDataset, get_transforms\n",
        "from src.model import create_model\n",
        "from src.client import HospitalClient, create_hospital_splits\n",
        "from src.utils import create_train_val_split, save_results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def get_model_parameters(model):\n",
        "    \"\"\"Extract model parameters\"\"\"\n",
        "    return [val.cpu().numpy() for val in model.state_dict().values()]\n",
        "\n",
        "\n",
        "def set_model_parameters(model, parameters):\n",
        "    \"\"\"Set model parameters\"\"\"\n",
        "    params_dict = zip(model.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def evaluate_global_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate global model on test set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss = 0.0\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    avg_loss = loss / len(test_loader)\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main federated learning pipeline\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"FEDERATED LEARNING EXPERIMENT - FedAvg\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ==================== CONFIGURATION ====================\n",
        "    config = {\n",
        "        # Data\n",
        "        'csv_file': '/content/drive/MyDrive/federated-dr/data/aptos/train.csv',\n",
        "        'img_dir': '/content/drive/MyDrive/federated-dr/data/aptos/train_images',\n",
        "        'val_split': 0.2,\n",
        "\n",
        "        # Federated Learning\n",
        "        'num_hospitals': 4,\n",
        "        'num_rounds': 30,  # FL rounds (start with 30 for testing)\n",
        "        'local_epochs': 3,  # Epochs per hospital per round\n",
        "        'fraction_fit': 1.0,  # Use all hospitals each round\n",
        "\n",
        "        # Model\n",
        "        'model_name': 'efficientnet_b0',\n",
        "        'num_classes': 5,\n",
        "        'pretrained': True,\n",
        "\n",
        "        # Training\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'num_workers': 2,\n",
        "\n",
        "        # Device\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "\n",
        "        # Paths\n",
        "        'save_dir': '/content/federated-dr/results/fedavg',\n",
        "    }\n",
        "\n",
        "    os.makedirs(config['save_dir'], exist_ok=True)\n",
        "\n",
        "    print(\"\\nConfiguration:\")\n",
        "    for key, value in config.items():\n",
        "        print(\"  {}: {}\".format(key, value))\n",
        "\n",
        "    device = torch.device(config['device'])\n",
        "\n",
        "    # ==================== PREPARE DATA ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Preparing Federated Data...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Load dataset\n",
        "    train_transform = get_transforms(mode='train')\n",
        "    val_transform = get_transforms(mode='val')\n",
        "\n",
        "    full_dataset = DiabeticRetinopathyDataset(\n",
        "        csv_file=config['csv_file'],\n",
        "        img_dir=config['img_dir'],\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    # Create train/val split\n",
        "    train_dataset, val_dataset = create_train_val_split(\n",
        "        full_dataset,\n",
        "        val_split=config['val_split'],\n",
        "        random_seed=42\n",
        "    )\n",
        "\n",
        "    # Split into hospitals (non-IID)\n",
        "    print(\"\\nCreating {} hospital datasets...\".format(config['num_hospitals']))\n",
        "    hospital_train_datasets = create_hospital_splits(\n",
        "        train_dataset,\n",
        "        num_hospitals=config['num_hospitals'],\n",
        "        random_seed=42\n",
        "    )\n",
        "\n",
        "    # Each hospital gets validation data too\n",
        "    hospital_val_datasets = create_hospital_splits(\n",
        "        val_dataset,\n",
        "        num_hospitals=config['num_hospitals'],\n",
        "        random_seed=43\n",
        "    )\n",
        "\n",
        "    # Create global test loader\n",
        "    test_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=False,\n",
        "        num_workers=config['num_workers']\n",
        "    )\n",
        "\n",
        "    print(\"\\nData preparation complete!\")\n",
        "\n",
        "    # ==================== DEFINE FL STRATEGY ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Setting up Federated Learning Strategy...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Create initial model\n",
        "    initial_model = create_model(\n",
        "        model_name=config['model_name'],\n",
        "        num_classes=config['num_classes'],\n",
        "        pretrained=config['pretrained']\n",
        "    )\n",
        "    initial_parameters = get_model_parameters(initial_model)\n",
        "\n",
        "    # Custom strategy that tracks results\n",
        "    class CustomFedAvg(fl.server.strategy.FedAvg):\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            super().__init__(*args, **kwargs)\n",
        "            self.round_results = []\n",
        "\n",
        "        def aggregate_fit(self, server_round, results, failures):\n",
        "            \"\"\"Aggregate and evaluate after each round\"\"\"\n",
        "            aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
        "                server_round, results, failures\n",
        "            )\n",
        "\n",
        "            if aggregated_parameters is not None:\n",
        "                # Evaluate global model\n",
        "                print(\"\\nEvaluating global model (Round {})...\".format(server_round))\n",
        "                model = create_model(\n",
        "                    model_name=config['model_name'],\n",
        "                    num_classes=config['num_classes'],\n",
        "                    pretrained=False  # Don't reload pretrained weights\n",
        "                )\n",
        "                set_model_parameters(\n",
        "                    model,\n",
        "                    fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
        "                )\n",
        "\n",
        "                loss, accuracy = evaluate_global_model(model, test_loader, device)\n",
        "\n",
        "                print(\"  Global Model - Loss: {:.4f}, Acc: {:.2f}%\".format(\n",
        "                    loss, accuracy))\n",
        "\n",
        "                # Store results\n",
        "                self.round_results.append({\n",
        "                    'round': server_round,\n",
        "                    'loss': loss,\n",
        "                    'accuracy': accuracy\n",
        "                })\n",
        "\n",
        "                # Save checkpoint every 10 rounds\n",
        "                if server_round % 10 == 0:\n",
        "                    checkpoint_path = os.path.join(\n",
        "                        config['save_dir'],\n",
        "                        'global_model_round_{}.pth'.format(server_round)\n",
        "                    )\n",
        "                    torch.save({\n",
        "                        'round': server_round,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'loss': loss,\n",
        "                        'accuracy': accuracy\n",
        "                    }, checkpoint_path)\n",
        "                    print(\"  Saved checkpoint\")\n",
        "\n",
        "            return aggregated_parameters, aggregated_metrics\n",
        "\n",
        "    strategy = CustomFedAvg(\n",
        "        fraction_fit=config['fraction_fit'],\n",
        "        fraction_evaluate=config['fraction_fit'],\n",
        "        min_fit_clients=config['num_hospitals'],\n",
        "        min_evaluate_clients=config['num_hospitals'],\n",
        "        min_available_clients=config['num_hospitals'],\n",
        "        initial_parameters=fl.common.ndarrays_to_parameters(initial_parameters),\n",
        "    )\n",
        "\n",
        "    # ==================== CREATE CLIENT FUNCTION ====================\n",
        "    def client_fn(cid: str) -> fl.client.Client:\n",
        "        \"\"\"Create a client for hospital with given ID\"\"\"\n",
        "        client_id = int(cid)\n",
        "\n",
        "        # Get this hospital's data\n",
        "        train_data = hospital_train_datasets[client_id]\n",
        "        val_data = hospital_val_datasets[client_id]\n",
        "\n",
        "        # Create dataloaders\n",
        "        train_loader = DataLoader(\n",
        "            train_data,\n",
        "            batch_size=config['batch_size'],\n",
        "            shuffle=True,\n",
        "            num_workers=config['num_workers']\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_data,\n",
        "            batch_size=config['batch_size'],\n",
        "            shuffle=False,\n",
        "            num_workers=config['num_workers']\n",
        "        )\n",
        "\n",
        "        # Create model for this client\n",
        "        model = create_model(\n",
        "            model_name=config['model_name'],\n",
        "            num_classes=config['num_classes'],\n",
        "            pretrained=config['pretrained']\n",
        "        )\n",
        "\n",
        "        # Create client\n",
        "        client = HospitalClient(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            device=device,\n",
        "            learning_rate=config['learning_rate'],\n",
        "            local_epochs=config['local_epochs']\n",
        "        )\n",
        "\n",
        "        return client.to_client()\n",
        "\n",
        "    # ==================== RUN FEDERATED LEARNING ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Starting Federated Learning...\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"{} hospitals\".format(config['num_hospitals']))\n",
        "    print(\"{} FL rounds\".format(config['num_rounds']))\n",
        "    print(\"{} local epochs per round\".format(config['local_epochs']))\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    start_time = datetime.now()\n",
        "\n",
        "    # Start simulation\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=config['num_hospitals'],\n",
        "        config=fl.server.ServerConfig(num_rounds=config['num_rounds']),\n",
        "        strategy=strategy,\n",
        "        client_resources={\n",
        "            \"num_cpus\": 2,\n",
        "            \"num_gpus\": 0.25 if device.type == 'cuda' else 0\n",
        "        }\n",
        "    )\n",
        "\n",
        "    end_time = datetime.now()\n",
        "    training_time = (end_time - start_time).total_seconds()\n",
        "\n",
        "    print(\"\\nTotal training time: {:.2f} minutes\".format(training_time / 60))\n",
        "\n",
        "    # ==================== ANALYZE RESULTS ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Analyzing Results...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Find best round\n",
        "    best_round = max(strategy.round_results, key=lambda x: x['accuracy'])\n",
        "    print(\"\\nBest round: {}\".format(best_round['round']))\n",
        "    print(\"  Accuracy: {:.2f}%\".format(best_round['accuracy']))\n",
        "    print(\"  Loss: {:.4f}\".format(best_round['loss']))\n",
        "\n",
        "    # ==================== VISUALIZE ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Creating Visualizations...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    rounds = [r['round'] for r in strategy.round_results]\n",
        "    accuracies = [r['accuracy'] for r in strategy.round_results]\n",
        "    losses = [r['loss'] for r in strategy.round_results]\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Accuracy plot\n",
        "    ax1.plot(rounds, accuracies, marker='o', linewidth=2)\n",
        "    ax1.set_xlabel('Round')\n",
        "    ax1.set_ylabel('Accuracy (%)')\n",
        "    ax1.set_title('Global Model Accuracy')\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Loss plot\n",
        "    ax2.plot(rounds, losses, marker='o', color='red', linewidth=2)\n",
        "    ax2.set_xlabel('Round')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.set_title('Global Model Loss')\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\n",
        "        os.path.join(config['save_dir'], 'training_curves.png'),\n",
        "        dpi=300,\n",
        "        bbox_inches='tight'\n",
        "    )\n",
        "    print(\"Saved training curves\")\n",
        "    plt.show()\n",
        "\n",
        "    # ==================== SAVE RESULTS ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Saving Results...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    final_results = {\n",
        "        'config': config,\n",
        "        'round_results': strategy.round_results,\n",
        "        'best_round': best_round,\n",
        "        'training_time_minutes': training_time / 60,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    save_results(\n",
        "        final_results,\n",
        "        os.path.join(config['save_dir'], 'results.json')\n",
        "    )\n",
        "\n",
        "    # ==================== SUMMARY ====================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EXPERIMENT SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"Final Accuracy: {:.2f}%\".format(best_round['accuracy']))\n",
        "    print(\"Training Time: {:.2f} minutes\".format(training_time / 60))\n",
        "    print(\"Results saved to: {}\".format(config['save_dir']))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\nFederated Learning experiment complete!\")\n",
        "    print(\"\\nNext steps:\")\n",
        "    print(\"1. Compare with baseline results\")\n",
        "    print(\"2. Analyze per-hospital performance\")\n",
        "    print(\"3. Try different number of rounds or local epochs\")\n",
        "\n",
        "    return final_results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        results = main()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nTraining interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(\"\\n\\nError occurred: {}\".format(e))\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "HtRfRk1erZJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Federated learning experiment script created!\")\n",
        "print(\"File: /content/federated-dr/experiments/fedavg.py\")"
      ],
      "metadata": {
        "id": "wmMMx7Y6rapQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/federated-dr/experiments/compare_results.py\n",
        "# experiments/compare_results.py\n",
        "\"\"\"\n",
        "COMPARISON ANALYSIS\n",
        "\n",
        "Compare baseline (centralized) vs federated learning results\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "def load_results(baseline_path, fedavg_path):\n",
        "    \"\"\"Load results from both experiments\"\"\"\n",
        "\n",
        "    with open(baseline_path, 'r') as f:\n",
        "        baseline = json.load(f)\n",
        "\n",
        "    with open(fedavg_path, 'r') as f:\n",
        "        fedavg = json.load(f)\n",
        "\n",
        "    return baseline, fedavg\n",
        "\n",
        "\n",
        "def compare_accuracy(baseline, fedavg, save_path=None):\n",
        "    \"\"\"Compare accuracy between methods\"\"\"\n",
        "\n",
        "    # Extract accuracies\n",
        "    baseline_acc = baseline['evaluation']['accuracy']\n",
        "    fedavg_acc = fedavg['best_round']['accuracy']\n",
        "\n",
        "    # Create comparison plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    methods = ['Centralized\\n(Baseline)', 'Federated Learning\\n(FedAvg)']\n",
        "    accuracies = [baseline_acc, fedavg_acc]\n",
        "    colors = ['#2ecc71', '#3498db']\n",
        "\n",
        "    bars = ax.bar(methods, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, acc in zip(bars, accuracies):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                '{:.2f}%'.format(acc),\n",
        "                ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
        "\n",
        "    ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    ax.set_title('Centralized vs Federated Learning Performance', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylim([0, 100])\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(\"Saved comparison plot to {}\".format(save_path))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Print comparison\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PERFORMANCE COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Centralized (Baseline): {:.2f}%\".format(baseline_acc))\n",
        "    print(\"Federated Learning:     {:.2f}%\".format(fedavg_acc))\n",
        "    print(\"Difference:             {:.2f}%\".format(baseline_acc - fedavg_acc))\n",
        "    print(\"Relative Performance:   {:.2f}%\".format(100 * fedavg_acc / baseline_acc))\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "def compare_training_time(baseline, fedavg):\n",
        "    \"\"\"Compare training time\"\"\"\n",
        "\n",
        "    baseline_time = baseline['training_time_minutes']\n",
        "    fedavg_time = fedavg['training_time_minutes']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TRAINING TIME COMPARISON\")\n",
        "    print(\"=\"=\"*60)\n",
        "    print(\"Centralized: {:.2f} minutes\".format(baseline_time))\n",
        "    print(\"Federated:   {:.2f} minutes\".format(fedavg_time))\n",
        "    print(\"Difference:  {:.2f} minutes\".format(fedavg_time - baseline_time))\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "def plot_learning_curves(baseline, fedavg, save_path=None):\n",
        "    \"\"\"Plot learning curves side by side\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "    # Baseline learning curves\n",
        "    baseline_epochs = range(1, len(baseline['history']['train_acc']) + 1)\n",
        "\n",
        "    axes[0].plot(baseline_epochs, baseline['history']['train_acc'],\n",
        "                 'b-', label='Train', linewidth=2)\n",
        "    axes[0].plot(baseline_epochs, baseline['history']['val_acc'],\n",
        "                 'r-', label='Val', linewidth=2)\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    axes[0].set_title('Centralized Training', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend(fontsize=11)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Federated learning curves\n",
        "    fl_rounds = [r['round'] for r in fedavg['round_results']]\n",
        "    fl_accs = [r['accuracy'] for r in fedavg['round_results']]\n",
        "\n",
        "    axes[1].plot(fl_rounds, fl_accs, 'g-', linewidth=2, marker='o', markersize=4)\n",
        "    axes[1].set_xlabel('FL Round', fontsize=12)\n",
        "    axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    axes[1].set_title('Federated Learning', fontsize=14, fontweight='bold')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(\"Saved learning curves to {}\".format(save_path))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def create_summary_table(baseline, fedavg, save_path=None):\n",
        "    \"\"\"Create summary table\"\"\"\n",
        "\n",
        "    data = {\n",
        "        'Method': ['Centralized', 'Federated (FedAvg)'],\n",
        "        'Accuracy (%)': [\n",
        "            baseline['evaluation']['accuracy'],\n",
        "            fedavg['best_round']['accuracy']\n",
        "        ],\n",
        "        'Kappa Score': [\n",
        "            baseline['evaluation']['kappa'],\n",
        "            fedavg['best_round'].get('kappa', 'N/A')\n",
        "        ],\n",
        "        'Training Time (min)': [\n",
        "            baseline['training_time_minutes'],\n",
        "            fedavg['training_time_minutes']\n",
        "        ],\n",
        "        'Data Sharing': ['Yes', 'No'],\n",
        "        'Privacy': ['Low', 'High']\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUMMARY TABLE\")\n",
        "    print(\"=\"*60)\n",
        "    print(df.to_string(index=False))\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if save_path:\n",
        "        df.to_csv(save_path, index=False)\n",
        "        print(\"\\nSaved summary table to {}\".format(save_path))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main comparison function\"\"\"\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"COMPARISON ANALYSIS: Baseline vs Federated Learning\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Paths\n",
        "    baseline_path = '/content/federated-dr/results/baseline/results.json'\n",
        "    fedavg_path = '/content/federated-dr/results/fedavg/results.json'\n",
        "    save_dir = '/content/federated-dr/results/comparison'\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Check if results exist\n",
        "    if not os.path.exists(baseline_path):\n",
        "        print(\"\\nERROR: Baseline results not found!\")\n",
        "        print(\"Please run baseline experiment first:\")\n",
        "        print(\"  %run experiments/baseline.py\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(fedavg_path):\n",
        "        print(\"\\nERROR: FedAvg results not found!\")\n",
        "        print(\"Please run federated experiment first:\")\n",
        "        print(\"  %run experiments/fedavg.py\")\n",
        "        return\n",
        "\n",
        "    # Load results\n",
        "    print(\"\\nLoading results...\")\n",
        "    baseline, fedavg = load_results(baseline_path, fedavg_path)\n",
        "    print(\"Results loaded successfully!\")\n",
        "\n",
        "    # Compare accuracy\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"1. ACCURACY COMPARISON\")\n",
        "    print(\"=\"*70)\n",
        "    compare_accuracy(\n",
        "        baseline,\n",
        "        fedavg,\n",
        "        save_path=os.path.join(save_dir, 'accuracy_comparison.png')\n",
        "    )\n",
        "\n",
        "    # Compare training time\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"2. TRAINING TIME COMPARISON\")\n",
        "    print(\"=\"*70)\n",
        "    compare_training_time(baseline, fedavg)\n",
        "\n",
        "    # Plot learning curves\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"3. LEARNING CURVES\")\n",
        "    print(\"=\"*70)\n",
        "    plot_learning_curves(\n",
        "        baseline,\n",
        "        fedavg,\n",
        "        save_path=os.path.join(save_dir, 'learning_curves.png')\n",
        "    )\n",
        "\n",
        "    # Create summary table\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"4. SUMMARY TABLE\")\n",
        "    print(\"=\"*70)\n",
        "    summary_df = create_summary_table(\n",
        "        baseline,\n",
        "        fedavg,\n",
        "        save_path=os.path.join(save_dir, 'summary_table.csv')\n",
        "    )\n",
        "\n",
        "    # Key insights\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"KEY INSIGHTS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    baseline_acc = baseline['evaluation']['accuracy']\n",
        "    fedavg_acc = fedavg['best_round']['accuracy']\n",
        "    accuracy_gap = baseline_acc - fedavg_acc\n",
        "    relative_perf = 100 * fedavg_acc / baseline_acc\n",
        "\n",
        "    print(\"\\n1. Performance:\")\n",
        "    print(\"   - Federated learning achieves {:.1f}% of centralized performance\".format(relative_perf))\n",
        "    print(\"   - Accuracy gap: {:.2f}%\".format(accuracy_gap))\n",
        "\n",
        "    if accuracy_gap < 5:\n",
        "        print(\"   - ‚úÖ EXCELLENT: Gap < 5% shows FL is highly effective!\")\n",
        "    elif accuracy_gap < 10:\n",
        "        print(\"   - ‚úÖ GOOD: Gap < 10% is acceptable for privacy-preserving ML\")\n",
        "    else:\n",
        "        print(\"   - ‚ö†Ô∏è  Consider: More FL rounds or better aggregation (FedProx)\")\n",
        "\n",
        "    print(\"\\n2. Privacy:\")\n",
        "    print(\"   - Centralized: Patient data shared (privacy risk)\")\n",
        "    print(\"   - Federated: NO data sharing (privacy preserved)\")\n",
        "    print(\"   - ‚úÖ FL enables collaborative learning while respecting privacy laws\")\n",
        "\n",
        "    print(\"\\n3. Real-World Applicability:\")\n",
        "    print(\"   - FL is viable for multi-hospital AI systems\")\n",
        "    print(\"   - Small performance cost for significant privacy gains\")\n",
        "    print(\"   - Ready for deployment in healthcare settings\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Comparison complete!\")\n",
        "    print(\"All results saved to: {}\".format(save_dir))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        print(\"\\nError: {}\".format(e))\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "y2wWq7usrdRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/federated-dr/test_setup.py\n",
        "# test_setup.py\n",
        "\"\"\"\n",
        "Test if everything is set up correctly\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/federated-dr')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TESTING PROJECT SETUP\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test 1: Import modules\n",
        "print(\"\\n1. Testing imports...\")\n",
        "try:\n",
        "    from src.dataset import DiabeticRetinopathyDataset, get_transforms\n",
        "    print(\"   ‚úÖ dataset.py\")\n",
        "except Exception as e:\n",
        "    print(\"   ‚ùå dataset.py: {}\".format(e))\n",
        "\n",
        "try:\n",
        "    from src.model import create_model\n",
        "    print(\"   ‚úÖ model.py\")\n",
        "except Exception as e:\n",
        "    print(\"   ‚ùå model.py: {}\".format(e))\n",
        "\n",
        "try:\n",
        "    from src.train import Trainer\n",
        "    print(\"   ‚úÖ train.py\")\n",
        "except Exception as e:\n",
        "    print(\"   ‚ùå train.py: {}\".format(e))\n",
        "\n",
        "try:\n",
        "    from src.client import HospitalClient\n",
        "    print(\"   ‚úÖ client.py\")\n",
        "except Exception as e:\n",
        "    print(\"   ‚ùå client.py: {}\".format(e))\n",
        "\n",
        "try:\n",
        "    from src.utils import create_train_val_split\n",
        "    print(\"   ‚úÖ utils.py\")\n",
        "except Exception as e:\n",
        "    print(\"   ‚ùå utils.py: {}\".format(e))\n",
        "\n",
        "# Test 2: Check data\n",
        "print(\"\\n2. Checking data availability...\")\n",
        "import os\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/federated-dr/data/aptos/train.csv'\n",
        "img_dir = '/content/drive/MyDrive/federated-dr/data/aptos/train_images'\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    print(\"   ‚úÖ train.csv found\")\n",
        "else:\n",
        "    print(\"   ‚ùå train.csv not found\")\n",
        "\n",
        "if os.path.exists(img_dir):\n",
        "    num_images = len(os.listdir(img_dir))\n",
        "    print(\"   ‚úÖ train_images found ({} images)\".format(num_images))\n",
        "else:\n",
        "    print(\"   ‚ùå train_images not found\")\n",
        "\n",
        "# Test 3: Check GPU\n",
        "print(\"\\n3. Checking GPU...\")\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"   ‚úÖ GPU available: {}\".format(torch.cuda.get_device_name(0)))\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è  No GPU (will use CPU - slower)\")\n",
        "\n",
        "# Test 4: Test dataset loading\n",
        "print(\"\\n4. Testing dataset loading...\")\n",
        "try:\n",
        "    transform = get_transforms(mode='train')\n",
        "    dataset = DiabeticRetinopathyDataset(csv_path, img_dir, transform)\n",
        "    image, label = dataset[0]\n",
        "    print(\"   ‚úÖ Dataset loads successfully\")\n",
        "    print(\"   ‚úÖ Image shape: {}\".format(image.shape))\n",
        "    print(\"   ‚úÖ Total samples: {}\".format(len(dataset)))\n",
        "except Exception as e:\n",
        "    print(\"   ‚ùå Dataset loading failed: {}\".format(e))\n",
        "\n",
        "# Test 5: Test model creation\n",
        "print(\"\\n5. Testing model creation...\")\n",
        "try:\n",
        "    model = create_model('efficientnet_b0', num_classes=5, pretrained=True)\n",
        "    print(\"   ‚úÖ Model created successfully\")\n",
        "\n",
        "    # Test forward pass\n",
        "    x = torch.randn(2, 3, 224, 224)\n",
        "    with torch.no_grad():\n",
        "        output = model(x)\n",
        "    print(\"   ‚úÖ Forward pass works (output shape: {})\".format(output.shape))\n",
        "except Exception as e:\n",
        "    print(\"   ‚ùå Model creation failed: {}\".format(e))\n",
        "\n",
        "# Test 6: Check Flower\n",
        "print(\"\\n6. Testing Flower (FL framework)...\")\n",
        "try:\n",
        "    import flwr as fl\n",
        "    print(\"   ‚úÖ Flower installed\")\n",
        "except Exception as e:\n",
        "    print(\"   ‚ùå Flower not installed: {}\".format(e))\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SETUP TEST COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print"
      ],
      "metadata": {
        "id": "_Vgjb20jrsxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run setup test\n",
        "%run /content/federated-dr/test_setup.py"
      ],
      "metadata": {
        "id": "IIQebWpIru_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting baseline experiment...\")\n",
        "print(\"This will take 30-45 minutes with GPU\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "%run /content/federated-dr/experiments/baseline.py"
      ],
      "metadata": {
        "id": "JIuYk3fDrxSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/federated-dr/src\n"
      ],
      "metadata": {
        "id": "Evid28685-M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/federated-dr/experiments/baseline.py\n",
        "\n"
      ],
      "metadata": {
        "id": "EslVPsQa6BmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python /content/federated-dr/experiments/baseline.py\n"
      ],
      "metadata": {
        "id": "ljsyh-Qb7C1R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}